{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:47:40,902 INFO     Agents loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:47:40,997 WARNING  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2023-04-17 20:47:40,999 INFO     Autoencoder loaded\n",
      "2023-04-17 20:47:41,007 INFO     Testing iteration 0\n",
      "2023-04-17 20:47:41,007 INFO     Data received from DU (dl_buffer [bytes], tx_brate downlink [Mbps], ratio_granted_req): \n",
      "2023-04-17 20:47:41,007 INFO     [[[1.43300e-07 1.04877e+00 2.36000e+02]\n",
      "  [1.91700e-07 1.21344e+00 2.35000e+02]\n",
      "  [9.69000e-08 9.86208e-01 1.23000e+02]\n",
      "  [1.76500e-07 9.84224e-01 6.46000e+02]\n",
      "  [0.00000e+00 1.24886e+00 3.05000e+02]\n",
      "  [4.50700e-07 8.88482e-01 3.90000e+02]\n",
      "  [2.93000e-08 1.29928e+00 4.70000e+02]\n",
      "  [0.00000e+00 9.70432e-01 4.09000e+02]\n",
      "  [0.00000e+00 9.82265e-01 5.45000e+02]\n",
      "  [2.97000e-08 1.05568e+00 6.85000e+02]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:47:41,238 INFO     Slice 0: Action is 1 Reward is: 1.067764\n",
      "2023-04-17 20:47:41,240 INFO     Testing iteration 1\n",
      "2023-04-17 20:47:41,240 INFO     Data received from DU (dl_buffer [bytes], tx_brate downlink [Mbps], ratio_granted_req): \n",
      "2023-04-17 20:47:41,241 INFO     [[[3.70000e-09 2.27149e-02 4.10000e+01]\n",
      "  [0.00000e+00 1.07520e-02 2.40000e+01]\n",
      "  [0.00000e+00 5.13600e-02 3.17000e+02]\n",
      "  [0.00000e+00 4.28800e-02 1.41000e+02]\n",
      "  [1.07000e-08 3.46667e-02 4.70000e+01]\n",
      "  [0.00000e+00 4.26667e-02 1.24000e+02]\n",
      "  [1.13000e-08 4.45760e-02 3.40000e+02]\n",
      "  [0.00000e+00 6.52530e-02 7.80000e+01]\n",
      "  [0.00000e+00 4.27200e-02 5.50000e+01]\n",
      "  [0.00000e+00 3.19680e-02 6.70000e+01]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:47:41,308 INFO     Slice 1: Action is 1 Reward is: 0.03895573\n",
      "2023-04-17 20:47:41,309 INFO     Testing iteration 2\n",
      "2023-04-17 20:47:41,309 INFO     Data received from DU (dl_buffer [bytes], tx_brate downlink [Mbps], ratio_granted_req): \n",
      "2023-04-17 20:47:41,310 INFO     [[[0.00000e+00 1.60000e-02 1.20000e+01]\n",
      "  [0.00000e+00 2.11200e-02 3.00000e+01]\n",
      "  [0.00000e+00 1.76640e-02 8.30000e+01]\n",
      "  [0.00000e+00 5.31200e-03 4.00000e+00]\n",
      "  [0.00000e+00 1.60000e-02 2.00000e+01]\n",
      "  [0.00000e+00 5.31200e-03 6.00000e+00]\n",
      "  [0.00000e+00 1.63534e-02 9.00000e+00]\n",
      "  [0.00000e+00 2.17189e-02 5.00000e+01]\n",
      "  [0.00000e+00 5.31200e-03 4.00000e+00]\n",
      "  [0.00000e+00 1.13280e-02 5.70000e+01]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 20:47:41,379 INFO     Slice 2: Action is 2 Reward is: 27.5\n",
      "2023-04-17 20:47:41,380 INFO     Sending this message to the DU: 1,1,2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 325\u001b[0m\n\u001b[0;32m    322\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m policies])\n\u001b[0;32m    323\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mSending this message to the DU: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m msg)\n\u001b[1;32m--> 325\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m10\u001b[39;49m)\n\u001b[0;32m    327\u001b[0m \u001b[39m# Users may want to plug in their own functions to send the DRL policies\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m# to the DU based on the specific DU implementation in use\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39m# send_action_to_DU(DU_address, msg)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "import absl\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Generating dataset from csv file. Returns a Pandas DataFrame\n",
    "def entire_dataset_from_single_file(filename,\n",
    "                                    col_names,\n",
    "                                    selected_col_names,\n",
    "                                    remove_zero_req_prb_entries=True,\n",
    "                                    scale_dl_buffer=True,\n",
    "                                    replace_zero_with_one=False,\n",
    "                                    add_prb_ratio=True):\n",
    "    dataset = pd.read_csv(filename, names=col_names, usecols=selected_col_names, header=0)\n",
    "\n",
    "    if remove_zero_req_prb_entries:\n",
    "        dataset = dataset.loc[dataset['sum_requested_prbs'] > 0].reset_index(drop=True)\n",
    "\n",
    "    if scale_dl_buffer and any([\"dl_buffer [bytes]\" in m for m in\n",
    "                                selected_col_names]):\n",
    "        # scale the dl_buffer\n",
    "        dataset['dl_buffer [bytes]'] = dataset['dl_buffer [bytes]'] / 100000\n",
    "\n",
    "    if add_prb_ratio:\n",
    "        dict_add = pd.DataFrame.from_dict({\"ratio_granted_req\": np.clip(np.nan_to_num(\n",
    "            dataset[\"sum_granted_prbs\"] / dataset[\"sum_requested_prbs\"]), a_min=0, a_max=1)\n",
    "        })\n",
    "        if replace_zero_with_one:\n",
    "            dict_add['ratio_granted_req'].loc[dataset['sum_requested_prbs'] <= 0] = 1.0\n",
    "        return dataset.join(dict_add)\n",
    "    else:\n",
    "        return dataset\n",
    "\n",
    "# return all csv files inside a single DataFrame\n",
    "def entire_dataset_from_folder(main_folder,\n",
    "                               wildcard,\n",
    "                               col_names,\n",
    "                               selected_col_names,\n",
    "                               scale_dl_buffer=True,\n",
    "                               remove_zero_req_prb_entries=True,\n",
    "                               replace_zero_with_one=False,\n",
    "                               add_prb_ratio=True):\n",
    "    dataset = []\n",
    "    for filename in glob.glob(main_folder + wildcard):\n",
    "        db_tmp = entire_dataset_from_single_file(filename, col_names=col_names,\n",
    "                                                 selected_col_names=selected_col_names,\n",
    "                                                 scale_dl_buffer=scale_dl_buffer,\n",
    "                                                 remove_zero_req_prb_entries=remove_zero_req_prb_entries,\n",
    "                                                 replace_zero_with_one=replace_zero_with_one,\n",
    "                                                 add_prb_ratio=add_prb_ratio)\n",
    "        dataset.append(db_tmp)\n",
    "\n",
    "    return pd.concat(dataset, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "# take n entries from the DataFrame at random\n",
    "def extract_n_entries_from_dataset(dataset=None,\n",
    "                                   slice_id=None,\n",
    "                                   n_entries=10,\n",
    "                                   metrics_export=None):\n",
    "    if slice_id is not None:\n",
    "        d_temp = dataset.loc[dataset['slice_id'] == int(slice_id)]\n",
    "    else:\n",
    "        d_temp = dataset\n",
    "\n",
    "    d_temp = d_temp.sample(n=n_entries).reset_index(drop=True)\n",
    "    if metrics_export is not None:\n",
    "        d_temp = d_temp[metrics_export]\n",
    "\n",
    "    return d_temp\n",
    "\n",
    "# This function is used here to emulate a DU reporting real-time data. Replace this function with your DU\n",
    "# FOR TESTING PURPOSES ONLY\n",
    "def get_data_from_DUs(dataset=None,\n",
    "                      n_entries=1000,\n",
    "                      n_col=4,\n",
    "                      slice_id=None,\n",
    "                      metrics_export=None):\n",
    "\n",
    "    if dataset is None:  # generate random data in case you do not have a dataset\n",
    "        values = np.random.random(size=(n_entries, n_col))\n",
    "        slice_id = np.random.randint(low=0, high=3, size=(n_entries, 1))\n",
    "        data = np.concatenate((slice_id, values), axis=1)\n",
    "    else:\n",
    "        data = extract_n_entries_from_dataset(dataset=dataset,\n",
    "                                              slice_id=slice_id,\n",
    "                                              n_entries=n_entries,\n",
    "                                              metrics_export=metrics_export)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Return lists for metrics, rewards, prbs assigned to each slice.\n",
    "# Ideally, the list is such that len(list) = num_slices\n",
    "def split_data(slice_profiles=None,\n",
    "               data_to_spit=None,\n",
    "               metric_list=None,\n",
    "               metric_dict=None,\n",
    "               n_entries_per_slice=None):\n",
    "    metrics = []\n",
    "    prbs = []\n",
    "    rewards = []\n",
    "\n",
    "    # ordering here follows slice_profiles\n",
    "    for i in slice_profiles:\n",
    "\n",
    "        slice_data = data_to_spit[data_to_spit[:, metric_dict['slice_id']] == slice_profiles[i]['slice_id'], :]\n",
    "\n",
    "        if slice_data.size > 0:\n",
    "            # repmat on rows to reach needed dimension in case you do not have enough reporting data\n",
    "            while slice_data.shape[0] < n_entries_per_slice:\n",
    "                slice_data = np.vstack((slice_data, np.zeros((1, slice_data.shape[1]))))\n",
    "\n",
    "            slice_prb = slice_data[:, metric_dict['slice_prb']]\n",
    "            slice_metrics = slice_data[:, [metric_dict[x] for x in metric_list]]\n",
    "            slice_reward = slice_data[:, metric_dict[slice_profiles[i]['reward_metric']]]\n",
    "\n",
    "            if n_entries_per_slice is not None:\n",
    "                slice_prb = slice_prb[0:n_entries_per_slice]\n",
    "                slice_metrics = slice_metrics[0:n_entries_per_slice, :]\n",
    "                slice_reward = slice_reward[0:n_entries_per_slice]\n",
    "        else:\n",
    "            slice_metrics = []\n",
    "            slice_prb = []\n",
    "            slice_reward = []\n",
    "\n",
    "        metrics.append(slice_metrics)\n",
    "        prbs.append(slice_prb)\n",
    "        rewards.append(slice_reward)\n",
    "\n",
    "    return metrics, prbs, rewards\n",
    "\n",
    "# Used to generate the input to the DRL agent. It returns a TimeStep that contains (step_type, reward, discount, observations)\n",
    "def generate_timestep_for_policy(obs_tmp=None):\n",
    "    step_type = tf.convert_to_tensor(\n",
    "        [0], dtype=tf.int32, name='step_type')\n",
    "    reward = tf.convert_to_tensor(\n",
    "        [0], dtype=tf.float32, name='reward')\n",
    "    discount = tf.convert_to_tensor(\n",
    "        [1], dtype=tf.float32, name='discount')\n",
    "    observations = tf.convert_to_tensor(\n",
    "        [obs_tmp], dtype=tf.float32, name='observations')\n",
    "    return ts.TimeStep(step_type, reward, discount, observations)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Column names in the srsLTE CSV dataset\n",
    "    all_metrics_list = [\"Timestamp\",\n",
    "                        \"num_ues\",\n",
    "                        \"IMSI\",\n",
    "                        \"RNTI\",\n",
    "                        \"empty_1\",\n",
    "                        \"slicing_enabled\",\n",
    "                        \"slice_id\",\n",
    "                        \"slice_prb\",\n",
    "                        \"power_multiplier\",\n",
    "                        \"scheduling_policy\",\n",
    "                        \"empty_2\",\n",
    "                        \"dl_mcs\",\n",
    "                        \"dl_n_samples\",\n",
    "                        \"dl_buffer [bytes]\",\n",
    "                        \"tx_brate downlink [Mbps]\",\n",
    "                        \"tx_pkts downlink\",\n",
    "                        \"tx_errors downlink (%)\",\n",
    "                        \"dl_cqi\",\n",
    "                        \"empty_3\",\n",
    "                        \"ul_mcs\",\n",
    "                        \"ul_n_samples\",\n",
    "                        \"ul_buffer [bytes]\",\n",
    "                        \"rx_brate uplink [Mbps]\",\n",
    "                        \"rx_pkts uplink\",\n",
    "                        \"rx_errors uplink (%)\",\n",
    "                        \"ul_rssi\",\n",
    "                        \"ul_sinr\",\n",
    "                        \"phr\",\n",
    "                        \"empty_4\",\n",
    "                        \"sum_requested_prbs\",\n",
    "                        \"sum_granted_prbs\",\n",
    "                        \"empty_5\",\n",
    "                        \"dl_pmi\",\n",
    "                        \"dl_ri\",\n",
    "                        \"ul_n\",\n",
    "                        \"ul_turbo_iters\"]\n",
    "\n",
    "    # Column names we need to extract from the dataset\n",
    "    metric_list_to_extract = [\"slice_id\",\n",
    "                              \"dl_buffer [bytes]\",\n",
    "                              \"tx_brate downlink [Mbps]\",\n",
    "                              \"sum_requested_prbs\",\n",
    "                              \"sum_granted_prbs\"]\n",
    "\n",
    "    # configure logger and console output\n",
    "    logging.basicConfig(level=logging.DEBUG, filename='./agent.log', filemode='a+',\n",
    "                        format='%(asctime)-15s %(levelname)-8s %(message)s')\n",
    "    formatter = logging.Formatter('%(asctime)-15s %(levelname)-8s %(message)s')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(logging.INFO)\n",
    "    console.setFormatter(formatter)\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    use_gpu_in_env = True\n",
    "    mtc_policy_filename = './ml_models/mtc_policy'\n",
    "    urllc_policy_filename = './ml_models/urllc_policy'\n",
    "    embb_policy_filename = './ml_models/embb_policy'\n",
    "    autoencoder_filename = './ml_models/encoder.h5'\n",
    "\n",
    "    # Location of the dataset we want to use (valid in offline testing ONLY)\n",
    "    main_folder = './slice_traffic/rome_static_close/tr10'\n",
    "    wildcard_match = '/*/*/slices_bs*/*_metrics.csv'\n",
    "\n",
    "    # get dataset for testing purposes only.\n",
    "    # This is used as this code does not run with hardware components.\n",
    "    # Not needed if getting data from real DUs\n",
    "    dataset = entire_dataset_from_folder(main_folder=main_folder,\n",
    "                                         wildcard=wildcard_match,\n",
    "                                         col_names=all_metrics_list,\n",
    "                                         selected_col_names=metric_list_to_extract)\n",
    "\n",
    "    # Input size to the autoencoder for dimentionality reduction\n",
    "    n_entries_for_autoencoder = 10\n",
    "\n",
    "    # set logging level + enable TF2 behavior\n",
    "    absl.logging.set_verbosity(absl.logging.INFO)\n",
    "    # select which GPU to use\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "    if use_gpu_in_env is False:\n",
    "        gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "        print(\"Num GPUs Available outside environments: \", len(gpu_devices))\n",
    "\n",
    "    # load policy, these are the folder where saved_model.pb is stored\n",
    "    drl_agents = [tf.saved_model.load(embb_policy_filename),\n",
    "                  tf.saved_model.load(mtc_policy_filename),\n",
    "                  tf.saved_model.load(urllc_policy_filename)]\n",
    "\n",
    "    absl.logging.info('Agents loaded')\n",
    "\n",
    "    autoencoder = tf.keras.models.load_model(autoencoder_filename)\n",
    "\n",
    "    absl.logging.info('Autoencoder loaded')\n",
    "\n",
    "    slice_profiles = {'embb': {'slice_id': 0, 'reward_metric': \"tx_brate downlink [Mbps]\"},\n",
    "                      'mtc': {'slice_id': 1, 'reward_metric': \"tx_brate downlink [Mbps]\"},\n",
    "                      'urllc': {'slice_id': 2, 'reward_metric': \"ratio_granted_req\"}}\n",
    "\n",
    "    metric_dict = {\"dl_buffer [bytes]\": 1,\n",
    "                   \"tx_brate downlink [Mbps]\": 2,\n",
    "                   \"ratio_granted_req\": 3,\n",
    "                   \"slice_id\": 0,\n",
    "                   \"slice_prb\": 4}\n",
    "\n",
    "    metric_list_for_agents = [\"dl_buffer [bytes]\",\n",
    "                   \"tx_brate downlink [Mbps]\",\n",
    "                   \"ratio_granted_req\"]\n",
    "\n",
    "    default_policy = 0\n",
    "    previous_policy = dict()\n",
    "    for _, val in slice_profiles.items():\n",
    "        previous_policy[val['slice_id']] = default_policy\n",
    "\n",
    "    previous_metrics = ''\n",
    "\n",
    "    while True:\n",
    "        policies = list()\n",
    "\n",
    "        # This is where data comes from the DUs.\n",
    "        # As an example, we extract data from the static dataset.\n",
    "        # Users may want to interface it with their own DUs\n",
    "        data = get_data_from_DUs(dataset=dataset,\n",
    "                                 n_entries=1000,\n",
    "                                 metrics_export=metric_list_to_extract).to_numpy()\n",
    "\n",
    "        data_tmp, prbs, rewards = split_data(slice_profiles=slice_profiles,\n",
    "                                             data_to_spit=data,\n",
    "                                             metric_dict=metric_dict,\n",
    "                                             metric_list=metric_list_for_agents,\n",
    "                                             n_entries_per_slice=n_entries_for_autoencoder)\n",
    "\n",
    "        for i in range(len(slice_profiles)):\n",
    "            if len(data_tmp[i]) > 0:\n",
    "                for row in data_tmp[i]:\n",
    "                    row[0] /= 100000\n",
    "\n",
    "                logging.info('Testing iteration ' + str(i))\n",
    "                logging.info('Data received from DU (dl_buffer [bytes], tx_brate downlink [Mbps], ratio_granted_req): ')\n",
    "                logging.info(np.expand_dims(data_tmp[i], axis=0))\n",
    "\n",
    "                obs_tmp = autoencoder.predict(np.expand_dims(data_tmp[i], axis=0)).astype('float32')\n",
    "                obs_tmp = np.append(obs_tmp, prbs[i][0]).astype('float32')\n",
    "\n",
    "                reward_mean = np.mean(rewards[i]).astype('float32')\n",
    "                time_step = generate_timestep_for_policy(obs_tmp)\n",
    "                action = drl_agents[i].action(time_step)\n",
    "\n",
    "                # append policies to send and store policy\n",
    "                policies.append(action[0][0][0].numpy())\n",
    "                previous_policy[i] = action[0][0][0].numpy()\n",
    "\n",
    "                logging.info('Slice ' + str(i) + ': Action is ' + str(action[0][0][0].numpy()) + ' Reward is: ' + str(\n",
    "                    reward_mean))\n",
    "            else:\n",
    "                # append previous policy\n",
    "                policies.append(previous_policy[i])\n",
    "                logging.info('Using previous action ' + str(previous_policy[i]) + ' for slice profile ' + str(i))\n",
    "\n",
    "        # build message to send policies to the DU\n",
    "        msg = ','.join([str(x) for x in policies])\n",
    "        logging.info('Sending this message to the DU: ' + msg)\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Users may want to plug in their own functions to send the DRL policies\n",
    "        # to the DU based on the specific DU implementation in use\n",
    "        # send_action_to_DU(DU_address, msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>지역명</th>\n",
       "      <th>규모구분</th>\n",
       "      <th>연도</th>\n",
       "      <th>월</th>\n",
       "      <th>분양가격(㎡)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>서울</td>\n",
       "      <td>전체</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>5841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울</td>\n",
       "      <td>전용면적 60㎡이하</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>서울</td>\n",
       "      <td>전용면적 60㎡초과 85㎡이하</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>5882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울</td>\n",
       "      <td>전용면적 85㎡초과 102㎡이하</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>5721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울</td>\n",
       "      <td>전용면적 102㎡초과</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>5879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>제주</td>\n",
       "      <td>전체</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>제주</td>\n",
       "      <td>전용면적 60㎡이하</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>4039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>제주</td>\n",
       "      <td>전용면적 60㎡초과 85㎡이하</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>제주</td>\n",
       "      <td>전용면적 85㎡초과 102㎡이하</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>제주</td>\n",
       "      <td>전용면적 102㎡초과</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>3601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4505 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     지역명               규모구분    연도   월 분양가격(㎡)\n",
       "0     서울                 전체  2015  10    5841\n",
       "1     서울         전용면적 60㎡이하  2015  10    5652\n",
       "2     서울   전용면적 60㎡초과 85㎡이하  2015  10    5882\n",
       "3     서울  전용면적 85㎡초과 102㎡이하  2015  10    5721\n",
       "4     서울        전용면적 102㎡초과  2015  10    5879\n",
       "...   ..                ...   ...  ..     ...\n",
       "4500  제주                 전체  2020   2    3955\n",
       "4501  제주         전용면적 60㎡이하  2020   2    4039\n",
       "4502  제주   전용면적 60㎡초과 85㎡이하  2020   2    3962\n",
       "4503  제주  전용면적 85㎡초과 102㎡이하  2020   2     NaN\n",
       "4504  제주        전용면적 102㎡초과  2020   2    3601\n",
       "\n",
       "[4505 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://bit.ly/ds-house-price')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_id</th>\n",
       "      <th>dl_buffer [bytes]</th>\n",
       "      <th>tx_brate downlink [Mbps]</th>\n",
       "      <th>sum_requested_prbs</th>\n",
       "      <th>sum_granted_prbs</th>\n",
       "      <th>ratio_granted_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035264</td>\n",
       "      <td>185</td>\n",
       "      <td>176</td>\n",
       "      <td>0.951351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287629</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287630</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287631</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287632</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287633</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287634 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        slice_id  dl_buffer [bytes]  tx_brate downlink [Mbps]   \n",
       "0              2                0.0                  0.015072  \\\n",
       "1              2                0.0                  0.015872   \n",
       "2              2                0.0                  0.035264   \n",
       "3              2                0.0                  0.015968   \n",
       "4              2                0.0                  0.015872   \n",
       "...          ...                ...                       ...   \n",
       "287629         2                0.0                  0.010624   \n",
       "287630         2                0.0                  0.022272   \n",
       "287631         2                0.0                  0.008096   \n",
       "287632         2                0.0                  0.010624   \n",
       "287633         2                0.0                  0.007168   \n",
       "\n",
       "        sum_requested_prbs  sum_granted_prbs  ratio_granted_req  \n",
       "0                        3                94           1.000000  \n",
       "1                       18                14           0.777778  \n",
       "2                      185               176           0.951351  \n",
       "3                       24                20           0.833333  \n",
       "4                        8                 8           1.000000  \n",
       "...                    ...               ...                ...  \n",
       "287629                   8                 8           1.000000  \n",
       "287630                  34                32           0.941176  \n",
       "287631                 103               102           0.990291  \n",
       "287632                  13                10           0.769231  \n",
       "287633                  68                80           1.000000  \n",
       "\n",
       "[287634 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 21:05:47,102 WARNING  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./ml_models/encoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
